{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing the Mosaic Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageFile, ImageDraw\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Allow PIL to open very large images\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "# Standardize the Background\n",
    "def standardize_background(image, bg_color=(255, 255, 255)):\n",
    "    \"\"\"\n",
    "    If the image has an alpha channel, composite it onto a white background.\n",
    "    Otherwise, convert to RGB.\n",
    "    \"\"\"\n",
    "    if image.mode in (\"RGBA\", \"LA\"):\n",
    "        background = Image.new(\"RGB\", image.size, bg_color)\n",
    "        background.paste(image, mask=image.split()[-1])\n",
    "        return background\n",
    "    else:\n",
    "        return image.convert(\"RGB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop to the Mosaic Content\n",
    "def crop_to_content(image, threshold=240):\n",
    "    \"\"\"\n",
    "    Crops out the white margins. Pixels with all channels above the threshold \n",
    "    are considered background.\n",
    "    \"\"\"\n",
    "    img_np = np.array(image)\n",
    "    # Create mask: True if any channel is less than threshold (i.e. non-white)\n",
    "    mask = (img_np[:,:,0] < threshold) | (img_np[:,:,1] < threshold) | (img_np[:,:,2] < threshold)\n",
    "    coords = np.argwhere(mask)\n",
    "    if coords.size == 0:\n",
    "        return image  # No content detected; return the original image\n",
    "    y0, x0 = coords.min(axis=0)\n",
    "    y1, x1 = coords.max(axis=0) + 1  # +1 to include the last pixel row/column\n",
    "    return image.crop((x0, y0, x1, y1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Image into Patches\n",
    "def split_into_patches(image, patch_size=640):\n",
    "    \"\"\"\n",
    "    Splits the image into patches on a grid.\n",
    "    If the patch at the right/bottom edge is smaller than patch_size,\n",
    "    it will remain at its natural size.\n",
    "    Returns a list of tuples: (patch, (x, y, width, height)).\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    width, height = image.size\n",
    "    for y in range(0, height, patch_size):\n",
    "        for x in range(0, width, patch_size):\n",
    "            # Ensure the box does not extend past the image dimensions\n",
    "            box = (x, y, min(x + patch_size, width), min(y + patch_size, height))\n",
    "            patch = image.crop(box)\n",
    "            patches.append((patch, box))\n",
    "    return patches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Out Mostly-White Patches\n",
    "def is_patch_valid(patch, bg_color=(255, 255, 255), tolerance=5, max_fraction=0.5):\n",
    "    \"\"\"\n",
    "    Returns True if less than max_fraction of the patch's pixels are within \n",
    "    tolerance of the background color.\n",
    "    \"\"\"\n",
    "    patch_np = np.array(patch)\n",
    "    # Boolean mask: True where pixel is close to background color\n",
    "    close_to_bg = np.all(np.abs(patch_np - bg_color) <= tolerance, axis=-1)\n",
    "    fraction_bg = np.mean(close_to_bg)\n",
    "    return fraction_bg < max_fraction, fraction_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Bounding Boxes on Image\n",
    "def draw_patch_boxes(image, patch_boxes, color=\"red\", width=2):\n",
    "    \"\"\"\n",
    "    image: PIL Image object\n",
    "    patch_boxes: list of bounding boxes (x1, y1, x2, y2)\n",
    "    color: outline color for the boxes\n",
    "    width: thickness of the rectangle outline\n",
    "    Returns a copy of `image` with rectangles drawn on it.\n",
    "    \"\"\"\n",
    "    # Make a copy so you don't modify the original in memory\n",
    "    drawn_image = image.copy()\n",
    "    draw = ImageDraw.Draw(drawn_image)\n",
    "    \n",
    "    for box in patch_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        # Draw the rectangle in the chosen color\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=width)\n",
    "    \n",
    "    return drawn_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_patches_downscaled(cropped_mosaic, valid_boxes, output_dir, max_dim=65500):\n",
    "    # 1. Check dimensions\n",
    "    w, h = cropped_mosaic.size\n",
    "    if w > max_dim or h > max_dim:\n",
    "        # 2. Compute a scale factor to fit within max_dim\n",
    "        scale_factor = min(max_dim / w, max_dim / h)\n",
    "        new_w = int(w * scale_factor)\n",
    "        new_h = int(h * scale_factor)\n",
    "        # 3. Resize the mosaic\n",
    "        mosaic_small = cropped_mosaic.resize((new_w, new_h), resample=Image.Resampling.BICUBIC)\n",
    "\n",
    "        # 4. Scale the bounding boxes\n",
    "        scaled_boxes = []\n",
    "        for (x1, y1, x2, y2) in valid_boxes:\n",
    "            sx1 = int(x1 * scale_factor)\n",
    "            sy1 = int(y1 * scale_factor)\n",
    "            sx2 = int(x2 * scale_factor)\n",
    "            sy2 = int(y2 * scale_factor)\n",
    "            scaled_boxes.append((sx1, sy1, sx2, sy2))\n",
    "\n",
    "        # 5. Draw the scaled boxes\n",
    "        mosaic_with_boxes = draw_patch_boxes(mosaic_small, scaled_boxes, color=\"yellow\", width=10)\n",
    "\n",
    "        # 6. Save\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        mosaic_with_boxes.save(os.path.join(output_dir, \"cropped_mosaic_with_patches_downscaled.jpg\"))\n",
    "        print(f\"Saved downscaled visualization to cropped_mosaic_with_patches_downscaled.jpg\")\n",
    "    else:\n",
    "        # If already within limits, just draw directly\n",
    "        mosaic_with_boxes = draw_patch_boxes(cropped_mosaic, valid_boxes, color=\"red\", width=2)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        mosaic_with_boxes.save(os.path.join(output_dir, \"cropped_mosaic_with_patches.jpg\"))\n",
    "        print(f\"Saved full-resolution visualization to cropped_mosaic_with_patches.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved downscaled visualization to cropped_mosaic_with_patches_downscaled.jpg\n",
      "Total patches generated: 243\n",
      "Valid patches (with content): 112\n"
     ]
    }
   ],
   "source": [
    "# Main Processing Pipeline\n",
    "def process_mosaic(image_path, patch_size=2000, output_dir=\"./patches\"):\n",
    "    # Load image\n",
    "    mosaic = Image.open(image_path)\n",
    "    \n",
    "    # Standardize the background to ensure consistency (white background)\n",
    "    mosaic = standardize_background(mosaic)\n",
    "    \n",
    "    # Crop the mosaic to only include the actual content (non-white areas)\n",
    "    cropped_mosaic = crop_to_content(mosaic)\n",
    "    \n",
    "    # Optionally, save the cropped mosaic for verification:\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "    # cropped_path = os.path.join(output_dir, \"cropped_mosaic.jpg\")\n",
    "    # cropped_mosaic.save(cropped_path)\n",
    "    \n",
    "    # Split into patches using a grid\n",
    "    all_patches = split_into_patches(cropped_mosaic, patch_size)\n",
    "    \n",
    "    # Filter valid patches\n",
    "    valid_patches = []\n",
    "    valid_boxes = []\n",
    "    for i, (patch, box) in enumerate(all_patches):\n",
    "        # TODO: Change tolerance and max_fraction\n",
    "        validity, fraction = is_patch_valid(patch, tolerance=5, max_fraction=0.5)\n",
    "        if validity:\n",
    "            valid_patches.append((patch, box))\n",
    "            valid_boxes.append(box)\n",
    "            # print(f\"Patch {i} is valid with fraction {fraction:.2f} being close to background.\")\n",
    "    \n",
    "    # Visualize patch boxes on the cropped mosaic\n",
    "    # Only drawing valid patch boxes, but you can draw all\n",
    "    # mosaic_with_boxes = draw_patch_boxes(cropped_mosaic, valid_boxes, color=\"yellow\", width=10)\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "    # mosaic_with_boxes.save(os.path.join(output_dir, \"cropped_mosaic_with_patches.jpg\"))\n",
    "    visualize_patches_downscaled(cropped_mosaic, valid_boxes, output_dir)\n",
    "    \n",
    "    # Save valid patches\n",
    "    for idx, (patch, box) in enumerate(valid_patches):\n",
    "        patch_filename = os.path.join(output_dir, f\"patch_{idx}_box_{box[0]}_{box[1]}_{box[2]}_{box[3]}.jpg\")\n",
    "        patch.save(patch_filename)\n",
    "    \n",
    "    print(f\"Total patches generated: {len(all_patches)}\")\n",
    "    print(f\"Valid patches (with content): {len(valid_patches)}\")\n",
    "    return valid_patches\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # image_path = \"./DC Mosaic 2.18.23.tif\"\n",
    "    image_path = \"./AL Mosaic 2.16.23.png\"\n",
    "    valid_patches = process_mosaic(image_path, patch_size=2500, output_dir=\"./patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the dimensions of an image\n",
    "# def get_image_dimensions(image_path):\n",
    "#     with Image.open(image_path) as img:\n",
    "#         return img.size  # Returns (width, height)\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     image_path = \"./DJI_0110.JPG\"  # Change this to your image path\n",
    "#     dimensions = get_image_dimensions(image_path)\n",
    "#     print(f\"Image dimensions: {dimensions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_np = np.array(valid_patches[42][0])\n",
    "# # For debugging, check min/max across each channel:\n",
    "# print(\"Min pixel values:\", patch_np.min(axis=(0,1)))\n",
    "# print(\"Max pixel values:\", patch_np.max(axis=(0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference On 1 Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "# # Run Inference on Each Patch with Roboflow\n",
    "# # Initialize Roboflow and your model. Replace with your API key, workspace, project, and version.\n",
    "# api_key = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "# rf = Roboflow(api_key)\n",
    "# project = rf.workspace().project(\"elephant-seals-project-mark-1\")\n",
    "# model = project.version(\"6\").model\n",
    "\n",
    "# total_clumps = 0\n",
    "# total_seals = 0\n",
    "\n",
    "# # for i, patch in enumerate(patches):\n",
    "# for i in range(0, 1):\n",
    "#     # Save the patch temporarily or use an in-memory file if supported by Roboflow.\n",
    "#     # patch_path = f\"patches/temp_patch_{i}.jpg\"\n",
    "#     patch_path = f\"./temp_patch_115.jpg\"\n",
    "#     # patch.save(patch_path)\n",
    "    \n",
    "#     # Run inference. Adjust confidence and overlap parameters as needed.\n",
    "#     result = model.predict(patch_path, confidence=0, overlap=0)\n",
    "\n",
    "#     result.plot()\n",
    "    \n",
    "#     # Assuming the response JSON has a \"predictions\" key with a list of detections.\n",
    "#     predictions = result.json().get(\"predictions\", [])\n",
    "\n",
    "    \n",
    "#     # Count predictions by class.\n",
    "#     clump_count = sum(1 for pred in predictions if pred[\"class\"] == \"clump\")\n",
    "#     seal_count = sum(1 for pred in predictions if pred[\"class\"] == \"seals\")\n",
    "    \n",
    "#     total_clumps += clump_count\n",
    "#     total_seals += seal_count\n",
    "\n",
    "# # --- 4. Output the Results ---\n",
    "# print(\"Total clumps detected:\", total_clumps)\n",
    "# print(\"Total seals detected:\", total_seals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
