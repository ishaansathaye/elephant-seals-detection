{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "from PIL import Image, ImageDraw\n",
    "import os \n",
    "import json \n",
    "import cv2 \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object detection api documentation: https://docs.roboflow.com/deploy/hosted-api/custom-models/object-detection\n",
    "api_key = \"132cxQxyrOVmPD63wJrV\" # api keys are individual, change to your own\n",
    "model_endpoint = \"\" # model endpoint (after deployment)\n",
    "version = 0 # version number\n",
    "\n",
    "rf = Roboflow(api_key=api_key)\n",
    "project = rf.workspace().project(\"MODEL_ENDPOINT\")\n",
    "model = project.version(version).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = \"\" # Your Image Folder Path Here\n",
    "seal_images = [os.path.join(image_folder_path, file) for file in os.listdir(image_folder_path)]\n",
    "\n",
    "Image.open(seal_images[0]) # for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust for model tendencies \n",
    "seal_conf = 20\n",
    "seal_overlap = 30\n",
    "clump_conf = 20\n",
    "clump_overlap = 30\n",
    "\n",
    "# extracting clumps \n",
    "clumps = []\n",
    "clump_size = []\n",
    "num_seals = [] # number of individual seals \n",
    "\n",
    "for img in seal_images:\n",
    "    image = Image.open(img)\n",
    "\n",
    "    seals = json.load(model.predict(img, confidence=seal_conf, overlap=seal_overlap, classes='seals').json())['predictions']\n",
    "    num_seals.append(len(seals))\n",
    "\n",
    "    clumps = json.loads(model.predict(img, confidence=clump_conf, overlap=clump_overlap, classes='clump').json())['predictions']\n",
    "\n",
    "    # getting individual seals\n",
    "    seal_pos = [] \n",
    "    for seal in seals:\n",
    "        x1_seal = seal['x'] - seal['width'] / 2\n",
    "        x2_seal = seal['x'] + seal['width'] / 2\n",
    "        y1_seal = seal['y'] - seal['height'] / 2\n",
    "        y2_seal = seal['y'] + seal['height'] / 2\n",
    "\n",
    "        seal_pos.append((x1_seal, y1_seal, x2_seal, y2_seal))\n",
    "    \n",
    "    # getting clumps \n",
    "    for clump in clumps:\n",
    "        x1_clump = clump['x'] - clump['width'] / 2\n",
    "        x2_clump = clump['x'] + clump['width'] / 2\n",
    "        y1_clump = clump['y'] - clump['height'] / 2\n",
    "        y2_clump = clump['y'] + clump['height'] / 2\n",
    "\n",
    "        top_left_clump = (x1_clump, y1_clump)\n",
    "        bottom_right_clump = (x2_clump, y2_clump)\n",
    "\n",
    "        for pos in seal_pos:\n",
    "            if (max(x1_clump, pos[0]) <= min(x2_clump, pos[2])) & (max(y1_clump, pos[1]) <= min(y2_clump, pos[3])):\n",
    "                seal_pos.remove(pos) \n",
    "        num_seals.append(len(seal_pos))\n",
    "\n",
    "        subimage = image.crop((*top_left_clump, *bottom_right_clump))\n",
    "\n",
    "        clumps.append(subimage)\n",
    "        clump_size.append(clump['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad and process clumps to df (ONLY FOR IMAGE MODEL APPROACH)\n",
    "def get_largest_dimensions(image_paths):\n",
    "    max_height, max_width = 0, 0\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        h, w, _ = img.shape\n",
    "        if h > max_height:\n",
    "            max_height = h\n",
    "        if w > max_width:\n",
    "            max_width = w\n",
    "    return max_height, max_width\n",
    "\n",
    "def preprocess_image(image_path, max_height, max_width):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    original_height, original_width = img.shape[:2]\n",
    "    padded_img = np.full((max_height, max_width, 3), (255, 0, 127), dtype=np.uint8)\n",
    "\n",
    "    y_offset = (max_height - original_height) // 2\n",
    "    x_offset = (max_width - original_width) // 2\n",
    "\n",
    "    padded_img[y_offset:y_offset + original_height, x_offset:x_offset + original_width] = img\n",
    "\n",
    "    padded_img = padded_img.astype(\"float32\") / 255.0\n",
    "\n",
    "    return padded_img\n",
    "\n",
    "\n",
    "def process_images_to_dataframe(image_paths, label):\n",
    "    data = []\n",
    "    max_height, max_width = get_largest_dimensions(image_paths)\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        padded_img = preprocess_image(img_path, max_height, max_width)\n",
    "        if padded_img is not None:\n",
    "            img_flattened = padded_img.flatten()\n",
    "            data.append(np.append(img_flattened, label))\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df = process_images_to_dataframe(clumps, clump_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/clumps_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
